{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PG1l_dw53oAj",
    "outputId": "3b1bfc4c-a9d9-401b-badc-bb7119dcf3c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\miniconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tf-keras in c:\\miniconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nathan adhitya\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow tf-keras -U\n",
    "%pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3egf2jR2t3n",
    "outputId": "c7a8062c-488e-48e6-ff67-2b2df13f3fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "VOCAB_SIZE = 512\n",
    "EMBEDDING_DIM = 128\n",
    "MAX_LENGTH = 32\n",
    "TRAINING_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "G0OThxTp3ARW"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titles-labelled-nathan.csv\")\n",
    "# Shuffle\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "train_size = int(len(df) * TRAINING_SPLIT)\n",
    "\n",
    "titles = df['title'].values\n",
    "labels = df['is_transaction'].values.astype(int)\n",
    "\n",
    "# Split them\n",
    "train_titles = titles[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "test_titles = titles[train_size:]\n",
    "test_labels = labels[train_size:]\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_titles, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_titles, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8000 sentence-label pairs for training.\n",
      "\n",
      "There are 2000 sentence-label pairs for validation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {train_dataset.cardinality()} sentence-label pairs for training.\\n\")\n",
    "print(f\"There are {test_dataset.cardinality()} sentence-label pairs for validation.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 512\n"
     ]
    }
   ],
   "source": [
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "\tmax_tokens=VOCAB_SIZE,\n",
    "    output_sequence_length=MAX_LENGTH,\n",
    "    pad_to_max_tokens=True,\n",
    ")\n",
    "\n",
    "vectorizer.adapt(train_dataset.map(lambda title, is_transaction: title))\n",
    "vocab_size = vectorizer.vocabulary_size()\n",
    "\n",
    "# Save vectorizer\n",
    "import pickle\n",
    "pickle.dump({'config': vectorizer.get_config(),\n",
    "             'vocabulary': vectorizer.get_vocabulary()}\n",
    "            , open(\"tv_layer.pkl\", \"wb\"))\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkout Pesanan dengan GoPay Tabungan by Jago Berhasil tanggal 19 September 2024 from:tokopedia.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "array([ 21,   4,  19,  14,  25,  26,  16,  17,  20, 380,  38,  15,   7,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0], dtype=int64)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(titles[0])\n",
    "vectorizer(titles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, text_vectorizer):\n",
    "    \"\"\"Apply the preprocessing to a dataset\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset): dataset to preprocess\n",
    "        text_vectorizer (tf.keras.layers.TextVectorization ): text vectorizer\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: transformed dataset\n",
    "    \"\"\"\n",
    "    # Convert the Dataset sentences to sequences, and encode the text labels\n",
    "    dataset = dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=32).batch(32)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the train dataset: 250\n",
      "Number of batches in the validation dataset: 63\n"
     ]
    }
   ],
   "source": [
    "train_proc_dataset = preprocess_dataset(train_dataset, vectorizer)\n",
    "test_proc_dataset = preprocess_dataset(test_dataset, vectorizer)\n",
    "\n",
    "print(f\"Number of batches in the train dataset: {train_proc_dataset.cardinality()}\")\n",
    "print(f\"Number of batches in the validation dataset: {test_proc_dataset.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5229 - val_accuracy: 0.9565 - val_loss: 0.1269\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.1602 - val_accuracy: 0.9585 - val_loss: 0.1296\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1472 - val_accuracy: 0.9600 - val_loss: 0.1137\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1274 - val_accuracy: 0.9600 - val_loss: 0.1088\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1266 - val_accuracy: 0.9630 - val_loss: 0.1177\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1244 - val_accuracy: 0.9645 - val_loss: 0.1084\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1150 - val_accuracy: 0.9615 - val_loss: 0.1040\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1148 - val_accuracy: 0.9645 - val_loss: 0.1072\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9597 - loss: 0.1139 - val_accuracy: 0.9615 - val_loss: 0.1079\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1147 - val_accuracy: 0.9645 - val_loss: 0.1101\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.0998\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(MAX_LENGTH,)),\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_proc_dataset, epochs=10, validation_data=test_proc_dataset)\n",
    "test_loss, test_acc = model.evaluate(test_proc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save('email_titles_nlp.keras')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
